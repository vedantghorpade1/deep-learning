{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ec6dc39-526e-48f1-bcd2-b0c3405d7832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Lambda\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29a4937a-d37b-486a-b1fb-88deda7c8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"I love to play football\", \"Football is a great game\", \"I enjoy watching football matches\", \"The team played well\", \"Football brings people together\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4984c52-f63d-44a3-bb3b-a269b787eb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love to play football\", \"Football is a great game\", \"I enjoy watching football matches\", \"The team played well\", \"Football brings people together']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = data.split('.')\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ba0db38-2ea6-432b-9722-eedb0b4633cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i love to play football football is a great game i enjoy watching football matches the team played well football brings people together']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sent = []\n",
    "for sentence in sentences:\n",
    "    if sentence==\"\":\n",
    "        continue\n",
    "    sentence=re.sub('[^a-zA-Z0-9]+', ' ', (sentence))\n",
    "    sentence=re.sub(r\"(?:^| )\\w (?:$| )\",' ', (sentence)).strip()\n",
    "    sentence=sentence.lower()\n",
    "    clean_sent.append(sentence)\n",
    "clean_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ecb03f6-b63c-4eed-8b63-5b86752b5627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 4, 5, 1, 1, 6, 7, 8, 9, 2, 10, 11, 1, 12, 13, 14, 15, 16, 1, 17, 18, 19]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_sent)\n",
    "sequences = tokenizer.texts_to_sequences(clean_sent)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85e96f05-295e-4b07-8c9d-88b5e71a32ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'i', 3: 'love', 4: 'to', 5: 'play', 1: 'football', 6: 'is', 7: 'a', 8: 'great', 9: 'game', 10: 'enjoy', 11: 'watching', 12: 'matches', 13: 'the', 14: 'team', 15: 'played', 16: 'well', 17: 'brings', 18: 'people', 19: 'together'} \n",
      "\n",
      "{'i': 2, 'love': 3, 'to': 4, 'play': 5, 'football': 1, 'is': 6, 'a': 7, 'great': 8, 'game': 9, 'enjoy': 10, 'watching': 11, 'matches': 12, 'the': 13, 'team': 14, 'played': 15, 'well': 16, 'brings': 17, 'people': 18, 'together': 19}\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {}\n",
    "word_to_index = {}\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    word_in_sentence = clean_sent[i].split()\n",
    "    for j, value in enumerate(sequence):\n",
    "        index_to_word[value] = word_in_sentence[j]\n",
    "        word_to_index[word_in_sentence[j]] = value\n",
    "print(index_to_word, \"\\n\")\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a2acebb-8cfc-4610-8dda-e4b43a2a6639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 5, 1], [3, 4, 1, 1], [4, 5, 1, 6], [5, 1, 6, 7], [1, 1, 7, 8], [1, 6, 8, 9], [6, 7, 9, 2], [7, 8, 2, 10], [8, 9, 10, 11], [9, 2, 11, 1], [2, 10, 1, 12], [10, 11, 12, 13], [11, 1, 13, 14], [1, 12, 14, 15], [12, 13, 15, 16], [13, 14, 16, 1], [14, 15, 1, 17], [15, 16, 17, 18], [16, 1, 18, 19]] \n",
      "\n",
      "[4, 5, 1, 1, 6, 7, 8, 9, 2, 10, 11, 1, 12, 13, 14, 15, 16, 1, 17]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "emb_size = 10\n",
    "context_size = 2\n",
    "contexts = []\n",
    "targets = []\n",
    "\n",
    "for sequence in sequences:\n",
    "    for i in range(context_size, len(sequence) - context_size):\n",
    "        target = sequence[i]\n",
    "        context = [sequence[i-2], sequence[i-1],sequence[i+1], sequence[i+2]]\n",
    "        contexts.append(context)\n",
    "        targets.append(target)\n",
    "print(contexts, \"\\n\")\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d54e055-244b-4159-9aeb-25b0d57c0d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'love', 'play', 'football']  ->  to\n",
      "['love', 'to', 'football', 'football']  ->  play\n",
      "['to', 'play', 'football', 'is']  ->  football\n",
      "['play', 'football', 'is', 'a']  ->  football\n",
      "['football', 'football', 'a', 'great']  ->  is\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    words = []\n",
    "    target = index_to_word.get(targets[i])\n",
    "    for j in contexts[i]:\n",
    "        words.append(index_to_word.get(j))\n",
    "    print(words, \" -> \", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dc23ab1a-d1a4-4f45-ad43-1567afc7f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(contexts)\n",
    "Y = np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "69d1d2c1-31d7-414e-ba05-9889ff2a06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=emb_size, input_length=2*context_size),\n",
    "    Lambda(lambda x: tf.reduce_mean(x, axis=1)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "034c2df0-f50b-4fe2-bd33-7ec72112d582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 2.9959\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2105 - loss: 2.9897\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2105 - loss: 2.9842\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2105 - loss: 2.9785\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2105 - loss: 2.9720\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2105 - loss: 2.9645\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2105 - loss: 2.9561\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2105 - loss: 2.9464\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2105 - loss: 2.9354\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2105 - loss: 2.9230\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, Y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f8c6edb-fb8f-4dee-ab05-811ce8b91223",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "Predicted word: football\n"
     ]
    }
   ],
   "source": [
    "def predict_word(model, context):\n",
    "    context = np.array(context).reshape(1, -1)\n",
    "    predictions = model.predict(context)\n",
    "    return index_to_word[np.argmax(predictions)]\n",
    "example_context = [1, 2, 4, 5]\n",
    "predicted_word = predict_word(model, example_context)\n",
    "print(f'Predicted word: {predicted_word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff859c-06dc-4515-8ab2-6b9850b4b0e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68df1b2-fd3d-477f-ac3a-f95053610a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910fb2f9-a6ce-495b-890b-68ee19312a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
